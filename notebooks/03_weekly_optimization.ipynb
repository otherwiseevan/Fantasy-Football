{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536a32be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 3: WEEKLY LINEUP OPTIMIZATION\n",
      "==================================================\n",
      "Dataset loaded: 6,670 records\n",
      "Positions: ['DEF', 'K', 'QB', 'RB', 'TE', 'WR']\n",
      "Weeks: 22 weeks\n",
      "\n",
      "Your league lineup requirements: {'QB': 1, 'RB': 2, 'WR': 2, 'TE': 1, 'FLEX1': 1, 'FLEX2': 1, 'K': 1, 'DEF': 1}\n",
      "Total starters: 10\n",
      "FLEX eligible positions: ['RB', 'WR', 'TE']\n",
      "\n",
      "Possible lineup combinations:\n",
      "- Max RBs: 4 (2 RB + 2 FLEX)\n",
      "- Max WRs: 4 (2 WR + 2 FLEX)\n",
      "- Max TEs: 3 (1 TE + 2 FLEX)\n",
      "- Always: 1 QB, 1 K, 1 DEF\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Weekly Lineup Optimization Setup\n",
    "# Create this in a new notebook: 03_weekly_optimization.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.optimize import linprog\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"PHASE 3: WEEKLY LINEUP OPTIMIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_pickle('../data/fantasy_data_2023.pkl')\n",
    "\n",
    "# Create metadata\n",
    "metadata = {\n",
    "    'positions': sorted(df['position'].unique().tolist()),\n",
    "    'weeks_covered': sorted(df['week'].unique().tolist()),\n",
    "    'total_records': len(df),\n",
    "    'unique_players': df['player_display_name'].nunique()\n",
    "}\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} records\")\n",
    "print(f\"Positions: {metadata['positions']}\")\n",
    "print(f\"Weeks: {len(metadata['weeks_covered'])} weeks\")\n",
    "\n",
    "# Your league lineup requirements (10 starters)\n",
    "lineup_requirements = {\n",
    "    'QB': 1,\n",
    "    'RB': 2,\n",
    "    'WR': 2,\n",
    "    'TE': 1,\n",
    "    'FLEX1': 1,  # RB/WR/TE\n",
    "    'FLEX2': 1,  # RB/WR/TE\n",
    "    'K': 1,\n",
    "    'DEF': 1\n",
    "}\n",
    "\n",
    "print(f\"\\nYour league lineup requirements: {lineup_requirements}\")\n",
    "print(f\"Total starters: {sum(lineup_requirements.values())}\")\n",
    "\n",
    "# Define flex eligibility\n",
    "flex_eligible_positions = ['RB', 'WR', 'TE']\n",
    "print(f\"FLEX eligible positions: {flex_eligible_positions}\")\n",
    "\n",
    "# potentially start:\n",
    "print(f\"\\nPossible lineup combinations:\")\n",
    "print(f\"- Max RBs: 4 (2 RB + 2 FLEX)\")\n",
    "print(f\"- Max WRs: 4 (2 WR + 2 FLEX)\")  \n",
    "print(f\"- Max TEs: 3 (1 TE + 2 FLEX)\")\n",
    "print(f\"- Always: 1 QB, 1 K, 1 DEF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be49c126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for weekly prediction models...\n",
      "Creating weekly features...\n",
      "Creating matchup features...\n",
      "Creating target variables...\n",
      "Modeling dataset shape: (5481, 19)\n",
      "Features available for weeks 3-22\n",
      "\n",
      "Building weekly prediction models...\n",
      "Clean modeling data: 5481 records\n",
      "Building QB model with 535 samples...\n",
      "QB - MAE: 6.15, RMSE: 7.83\n",
      "Building RB model with 1146 samples...\n",
      "RB - MAE: 5.18, RMSE: 6.92\n",
      "Building WR model with 1910 samples...\n",
      "WR - MAE: 5.34, RMSE: 7.28\n",
      "Building TE model with 899 samples...\n",
      "TE - MAE: 4.27, RMSE: 5.55\n",
      "\n",
      "Weekly prediction models built for ['QB', 'RB', 'WR', 'TE']\n",
      "\n",
      "Model performance:\n",
      "QB: MAE=6.15, RMSE=7.83 (535 samples)\n",
      "RB: MAE=5.18, RMSE=6.92 (1146 samples)\n",
      "WR: MAE=5.34, RMSE=7.28 (1910 samples)\n",
      "TE: MAE=4.27, RMSE=5.55 (899 samples)\n",
      "\n",
      "Next: Lineup optimization algorithms\n"
     ]
    }
   ],
   "source": [
    "# Weekly Performance Features\n",
    "\n",
    "def create_weekly_features(df):\n",
    "    \"\"\"Create features for predicting weekly performance\"\"\"\n",
    "    \n",
    "    # Sort by player and week\n",
    "    df_sorted = df.sort_values(['player_display_name', 'week'])\n",
    "    \n",
    "    # Rolling averages (last N games)\n",
    "    for window in [3, 5]:\n",
    "        df_sorted[f'rolling_avg_{window}w'] = df_sorted.groupby('player_display_name')['custom_fantasy_points'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean().shift(1)\n",
    "        )\n",
    "    \n",
    "    # Recent trend (slope of last 3 games)\n",
    "    def calculate_recent_trend(group):\n",
    "        trends = []\n",
    "        for i in range(len(group)):\n",
    "            if i < 2:\n",
    "                trends.append(0)\n",
    "            else:\n",
    "                recent_points = group['custom_fantasy_points'].iloc[max(0, i-2):i+1].values\n",
    "                if len(recent_points) >= 2:\n",
    "                    x = np.arange(len(recent_points))\n",
    "                    slope = np.polyfit(x, recent_points, 1)[0]\n",
    "                    trends.append(slope)\n",
    "                else:\n",
    "                    trends.append(0)\n",
    "        return pd.Series(trends, index=group.index)\n",
    "    \n",
    "    df_sorted['recent_trend'] = df_sorted.groupby('player_display_name').apply(calculate_recent_trend).reset_index(drop=True)\n",
    "    \n",
    "    # Games since last big game (>20 points)\n",
    "    df_sorted['games_since_boom'] = 0\n",
    "    for player in df_sorted['player_display_name'].unique():\n",
    "        player_mask = df_sorted['player_display_name'] == player\n",
    "        player_data = df_sorted[player_mask].copy()\n",
    "        \n",
    "        games_since = 0\n",
    "        for idx in player_data.index:\n",
    "            df_sorted.loc[idx, 'games_since_boom'] = games_since\n",
    "            if df_sorted.loc[idx, 'custom_fantasy_points'] > 20:\n",
    "                games_since = 0\n",
    "            else:\n",
    "                games_since += 1\n",
    "    \n",
    "    # Season week (early/mid/late season effects)\n",
    "    df_sorted['season_week'] = df_sorted['week']\n",
    "    df_sorted['is_early_season'] = (df_sorted['week'] <= 6).astype(int)\n",
    "    df_sorted['is_late_season'] = (df_sorted['week'] >= 15).astype(int)\n",
    "    \n",
    "    return df_sorted\n",
    "\n",
    "def create_matchup_features(df):\n",
    "    \"\"\"Create opponent/matchup-based features\"\"\"\n",
    "    \n",
    "    # This would ideally use strength of schedule data\n",
    "    # For now, we'll create simplified features\n",
    "    \n",
    "    # Opponent team (we'll encode this later)\n",
    "    df['opponent'] = df['opponent_team'] if 'opponent_team' in df.columns else 'Unknown'\n",
    "    \n",
    "    # Home/away (if available in your data)\n",
    "    # For now, we'll create a placeholder\n",
    "    df['is_home'] = np.random.choice([0, 1], size=len(df))  # Placeholder\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_target_variables(df):\n",
    "    \"\"\"Create different target variables for different prediction tasks\"\"\"\n",
    "    \n",
    "    # Main target: actual fantasy points\n",
    "    df['target_points'] = df['custom_fantasy_points']\n",
    "    \n",
    "    # Binary targets for different thresholds\n",
    "    df['hit_projection'] = (df['custom_fantasy_points'] > df['custom_fantasy_points'].mean()).astype(int)\n",
    "    df['boom_game'] = (df['custom_fantasy_points'] > 20).astype(int)  # Arbitrary threshold\n",
    "    df['bust_game'] = (df['custom_fantasy_points'] < 5).astype(int)   # Arbitrary threshold\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_modeling_data(df):\n",
    "    \"\"\"Prepare data for weekly prediction models\"\"\"\n",
    "    \n",
    "    # Feature engineering\n",
    "    print(\"Creating weekly features...\")\n",
    "    df_features = create_weekly_features(df)\n",
    "    \n",
    "    print(\"Creating matchup features...\")\n",
    "    df_features = create_matchup_features(df_features)\n",
    "    \n",
    "    print(\"Creating target variables...\")\n",
    "    df_features = create_target_variables(df_features)\n",
    "    \n",
    "    # Filter out first few weeks per player (need history for features)\n",
    "    df_modeling = df_features.groupby('player_display_name').apply(\n",
    "        lambda x: x.iloc[2:] if len(x) > 2 else x.iloc[0:0]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Modeling dataset shape: {df_modeling.shape}\")\n",
    "    print(f\"Features available for weeks {df_modeling['week'].min()}-{df_modeling['week'].max()}\")\n",
    "    \n",
    "    return df_modeling\n",
    "\n",
    "def build_weekly_prediction_models(df_modeling):\n",
    "    \"\"\"Build models to predict weekly performance\"\"\"\n",
    "    \n",
    "    # Feature columns for modeling\n",
    "    feature_cols = [\n",
    "        'rolling_avg_3w', 'rolling_avg_5w', 'recent_trend', 'games_since_boom',\n",
    "        'season_week', 'is_early_season', 'is_late_season', 'is_home'\n",
    "    ]\n",
    "    \n",
    "    # Remove any rows with missing features\n",
    "    df_clean = df_modeling.dropna(subset=feature_cols + ['target_points'])\n",
    "    \n",
    "    if len(df_clean) == 0:\n",
    "        print(\"No valid data for modeling\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Clean modeling data: {len(df_clean)} records\")\n",
    "    \n",
    "    # Build position-specific models\n",
    "    models = {}\n",
    "    model_metrics = {}\n",
    "    \n",
    "    for position in ['QB', 'RB', 'WR', 'TE']:\n",
    "        pos_data = df_clean[df_clean['position'] == position]\n",
    "        \n",
    "        if len(pos_data) < 50:  # Need minimum samples\n",
    "            print(f\"Insufficient data for {position}: {len(pos_data)} samples\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Building {position} model with {len(pos_data)} samples...\")\n",
    "        \n",
    "        X = pos_data[feature_cols]\n",
    "        y = pos_data['target_points']\n",
    "        \n",
    "        # Split data (use later weeks for testing)\n",
    "        split_week = pos_data['week'].quantile(0.7)\n",
    "        train_mask = pos_data['week'] <= split_week\n",
    "        \n",
    "        X_train, X_test = X[train_mask], X[~train_mask]\n",
    "        y_train, y_test = y[train_mask], y[~train_mask]\n",
    "        \n",
    "        if len(X_test) == 0:\n",
    "            print(f\"No test data for {position}\")\n",
    "            continue\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Train model\n",
    "        model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "        models[position] = {'model': model, 'scaler': scaler}\n",
    "        model_metrics[position] = {'MAE': mae, 'RMSE': rmse, 'samples': len(pos_data)}\n",
    "        \n",
    "        print(f\"{position} - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    return models, model_metrics\n",
    "\n",
    "# Execute the weekly prediction pipeline\n",
    "print(\"Preparing data for weekly prediction models...\")\n",
    "df_modeling = prepare_modeling_data(df)\n",
    "\n",
    "print(\"\\nBuilding weekly prediction models...\")\n",
    "weekly_models, metrics = build_weekly_prediction_models(df_modeling)\n",
    "\n",
    "if weekly_models:\n",
    "    print(f\"\\nWeekly prediction models built for {list(weekly_models.keys())}\")\n",
    "    print(\"\\nModel performance:\")\n",
    "    for pos, metric in metrics.items():\n",
    "        print(f\"{pos}: MAE={metric['MAE']:.2f}, RMSE={metric['RMSE']:.2f} ({metric['samples']} samples)\")\n",
    "else:\n",
    "    print(\"No weekly models could be built\")\n",
    "\n",
    "print(f\"\\nNext: Lineup optimization algorithms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a2b22f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantasyfootball-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
